{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pwd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "from scipy import optimize\n",
    "from scipy import constants\n",
    "hbar = constants.hbar\n",
    "\n",
    "import decay_widths as dw\n",
    "\n",
    "def get_username():\n",
    "    return pwd.getpwuid(os.getuid())[0]\n",
    "os.chdir(\"/uboone/data/users/{}/workdir/\".format(get_username()))\n",
    "\n",
    "LAMBDA = 1e6 # MeV, energy scale (1 TeV, used in https://arxiv.org/pdf/2202.03447.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_RSE_indices(pkl_data, uproot_file,columns=[0,1,2]):\n",
    "    test_run = pkl_data['run_ls'].to_numpy()\n",
    "    test_subrun = pkl_data['sub_ls'].to_numpy()\n",
    "    test_event = pkl_data['evt_ls'].to_numpy()\n",
    "\n",
    "    keys = uproot_file.keys()\n",
    "    data = uproot_file[keys[0]]\n",
    "    keys = data.keys()\n",
    "    runs = data[keys[columns[0]]].array()\n",
    "    subruns = data[keys[columns[1]]].array()\n",
    "    event = data[keys[columns[2]]].array()\n",
    "\n",
    "    indices = []\n",
    "    for i, run in enumerate(test_run):\n",
    "        run_args = np.where(runs==run)\n",
    "        subrun_args = np.where(subruns==test_subrun[i])\n",
    "        event_arg = np.where(event==test_event[i])\n",
    "        shared_run_sub_arg = np.intersect1d(run_args, subrun_args)\n",
    "        shared_arg = np.intersect1d(shared_run_sub_arg, event_arg)\n",
    "        indices.append(shared_arg[0])\n",
    "    return indices\n",
    "\n",
    "\n",
    "def check_matching_vtx(vtx_1, vtx_2, tolerance = 10**-7):\n",
    "    diff = np.abs(vtx_1-vtx_2)\n",
    "    mag_diff = diff/np.abs(vtx_2)\n",
    "    warning_indices = np.where(mag_diff>tolerance)\n",
    "    return warning_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_points = np.asarray([100,125,130,135,140,145,150,200]) # MeV\n",
    "theta_values = np.asarray([5.36,5.5,5.54,5.58, 5.63, 5.68, 5.73, 5.68])*10**-4\n",
    "decay_pos = ['KDAR', 'KDIF']\n",
    "runs = [1,3]\n",
    "shrs = [1,2]\n",
    "\n",
    "data_pkl = {}\n",
    "### Importing pkl files, variations of which are defined above\n",
    "for run in runs:\n",
    "    for pos in decay_pos:\n",
    "        for mass in mass_points:\n",
    "            for shr in shrs:\n",
    "                filepath =  'HPS_uboone_analysis/BDT_inputs_pkl/AllVar_Selected_Run{}_NuMI_Signal_{}_{}_{}shr_PPFX_pred_NEW.pkl'.format(run,pos,mass,shr)\n",
    "                name = \"Run{}_{}_{}_{}\".format(run,pos,mass,shr)\n",
    "                data_pkl[name] = pd.read_pickle(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run1_KDAR_100_1 ran successfully.\n",
      "Run1_KDAR_100_2 ran successfully.\n",
      "Run1_KDAR_125_1 ran successfully.\n",
      "Run1_KDAR_125_2 ran successfully.\n",
      "Run1_KDAR_130_1 ran successfully.\n",
      "Run1_KDAR_130_2 ran successfully.\n",
      "Run1_KDAR_135_1 ran successfully.\n",
      "Run1_KDAR_135_2 ran successfully.\n",
      "Run1_KDAR_140_1 ran successfully.\n",
      "Run1_KDAR_140_2 ran successfully.\n",
      "Run1_KDAR_145_1 ran successfully.\n",
      "Run1_KDAR_145_2 ran successfully.\n",
      "Run1_KDAR_150_1 ran successfully.\n",
      "Run1_KDAR_150_2 ran successfully.\n",
      "Run1_KDAR_200_1 ran successfully.\n",
      "Run1_KDAR_200_2 ran successfully.\n",
      "Run1_KDIF_100_1 ran successfully.\n",
      "Run1_KDIF_100_2 ran successfully.\n",
      "Run1_KDIF_125_1 ran successfully.\n",
      "Run1_KDIF_125_2 ran successfully.\n",
      "Run1_KDIF_130_1 ran successfully.\n",
      "Run1_KDIF_130_2 ran successfully.\n",
      "Run1_KDIF_135_1 ran successfully.\n",
      "Run1_KDIF_135_2 ran successfully.\n",
      "Run1_KDIF_140_1 ran successfully.\n",
      "Run1_KDIF_140_2 ran successfully.\n",
      "Run1_KDIF_145_1 ran successfully.\n",
      "Run1_KDIF_145_2 ran successfully.\n",
      "Run1_KDIF_150_1 ran successfully.\n",
      "Run1_KDIF_150_2 ran successfully.\n",
      "Run1_KDIF_200_1 ran successfully.\n",
      "Run1_KDIF_200_2 ran successfully.\n",
      "Run3_KDAR_100_1 ran successfully.\n",
      "Run3_KDAR_100_2 ran successfully.\n",
      "Run3_KDAR_125_1 ran successfully.\n",
      "Run3_KDAR_125_2 ran successfully.\n",
      "Run3_KDAR_130_1 ran successfully.\n",
      "Run3_KDAR_130_2 ran successfully.\n",
      "Run3_KDAR_135_1 ran successfully.\n",
      "Run3_KDAR_135_2 ran successfully.\n",
      "Run3_KDAR_140_1 ran successfully.\n",
      "Run3_KDAR_140_2 ran successfully.\n",
      "Run3_KDAR_145_1 ran successfully.\n",
      "Run3_KDAR_145_2 ran successfully.\n",
      "Run3_KDAR_150_1 ran successfully.\n",
      "Run3_KDAR_150_2 ran successfully.\n",
      "Run3_KDAR_200_1 ran successfully.\n",
      "Run3_KDAR_200_2 ran successfully.\n",
      "Run3_KDIF_100_1 ran successfully.\n",
      "Run3_KDIF_100_2 ran successfully.\n",
      "Run3_KDIF_125_1 ran successfully.\n",
      "Run3_KDIF_125_2 ran successfully.\n",
      "Run3_KDIF_130_1 ran successfully.\n",
      "Run3_KDIF_130_2 ran successfully.\n",
      "Run3_KDIF_135_1 ran successfully.\n",
      "Run3_KDIF_135_2 ran successfully.\n",
      "Run3_KDIF_140_1 ran successfully.\n",
      "Run3_KDIF_140_2 ran successfully.\n",
      "Run3_KDIF_145_1 ran successfully.\n",
      "Run3_KDIF_145_2 ran successfully.\n",
      "Run3_KDIF_150_1 ran successfully.\n",
      "Run3_KDIF_150_2 ran successfully.\n",
      "Run3_KDIF_200_1 ran successfully.\n",
      "Run3_KDIF_200_2 ran successfully.\n"
     ]
    }
   ],
   "source": [
    "for sig_key, sig_data in zip(data_pkl.keys(), data_pkl.values()):\n",
    "    run, K_label, mass_scalar, num_shrs = sig_key.split('_')\n",
    "    if run == 'Run1': horn_config = 'fhc'\n",
    "    if run == 'Run3': horn_config = 'rhc'\n",
    "    \n",
    "    tof_file = f\"tof_{horn_config}_{mass_scalar}.root\"\n",
    "    train_file = f\"sfn_numi_{horn_config}_generic_{mass_scalar}_ppfx_CV_train.root\"\n",
    "\n",
    "    with uproot.open(\"HPS_uboone_analysis/Final_v51_FHC/\"+train_file) as train_data:\n",
    "        keys = train_data.keys()\n",
    "        train_data = train_data[keys[0]]\n",
    "        \n",
    "        indices_2 = match_RSE_indices(sig_data, train_data, columns=[1,2,3])\n",
    "        \n",
    "        keys = train_data.keys()\n",
    "        train_data = train_data[keys[0]]\n",
    "        keys = train_data.keys()\n",
    "\n",
    "        \n",
    "        true_nu_vtx_x = train_data['true_nu_vtx_x'].array()[indices_2].to_numpy()\n",
    "        true_nu_vtx_y = train_data['true_nu_vtx_y'].array()[indices_2].to_numpy()\n",
    "        true_nu_vtx_z = train_data['true_nu_vtx_z'].array()[indices_2].to_numpy()\n",
    "        true_nu_vtx = [true_nu_vtx_x,true_nu_vtx_y,true_nu_vtx_z]\n",
    "\n",
    "    with uproot.open(\"HPS_uboone_analysis/TOF_input_root/\"+tof_file) as tof_data:\n",
    "        indices_1 = match_RSE_indices(sig_data, tof_data)\n",
    "        keys = tof_data.keys()\n",
    "        tof_data = tof_data[keys[0]]\n",
    "        keys = tof_data.keys()\n",
    "\n",
    "        vtx_x = tof_data['vtx_x'].array()[indices_1].to_numpy()\n",
    "        vtx_y = tof_data['vtx_y'].array()[indices_1].to_numpy()\n",
    "        vtx_z = tof_data['vtx_z'].array()[indices_1].to_numpy()\n",
    "\n",
    "        vtx = [vtx_x, vtx_y, vtx_z]\n",
    "\n",
    "        bad_indices = False\n",
    "        for i in range(3):\n",
    "            indices = check_matching_vtx(vtx[i], true_nu_vtx[i], tolerance=1e-7)\n",
    "            if np.shape(indices)[1]>0:\n",
    "                bad_indices=True\n",
    "            if bad_indices:\n",
    "                print(f\"{sig_key} error:\\n\")\n",
    "                print(f\"Files disagree on vertex coodrinates:\")\n",
    "                for index in indices:\n",
    "                    print(f\"{index}:\\n vtx = {vtx[i][index]}\\n tru_nu_vtx = {true_nu_vtx[i][index]}\\n diff = {np.abs(vtx[i][index]-true_nu_vtx[i][index])}\")\n",
    "\n",
    "\n",
    "        if not bad_indices:\n",
    "            print(f\"{sig_key} ran successfully.\")\n",
    "            tof = tof_data['proper_tof'].array()[indices_1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
